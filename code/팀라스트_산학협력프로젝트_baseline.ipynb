{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4A1l0jX4W4Cp"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import glob\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "import torchvision.models as models\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0WXovVmW4U5"
      },
      "outputs": [],
      "source": [
        "CFG = {\n",
        "    'IMG_SIZE':224,\n",
        "    'EPOCHS':5,\n",
        "    'LEARNING_RATE':3e-4,\n",
        "    'BATCH_SIZE':32,\n",
        "    'SEED':41\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEirAZZ9W4Ys"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(CFG['SEED']) # Seed 고정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayKuWnkiW4a1"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('./train.csv')\n",
        "\n",
        "train_len = int(len(df) * 0.8)\n",
        "train_df = df.iloc[:train_len]\n",
        "val_df = df.iloc[train_len:]\n",
        "\n",
        "train_label_vec = train_df.iloc[:,2:].values.astype(np.float32)\n",
        "val_label_vec = val_df.iloc[:,2:].values.astype(np.float32)\n",
        "\n",
        "CFG['label_size'] = train_label_vec.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WlAjAnv5W4c2",
        "outputId": "1c1db51c-e456-4eb7-b248-d46703bc5c24"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-1-bee92595b064>, line 97)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-bee92595b064>\"\u001b[0;36m, line \u001b[0;32m97\u001b[0m\n\u001b[0;31m    Model Define\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import glob\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "import torchvision.models as models\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "#Hyperparameter Setting\n",
        "CFG = {\n",
        "    'IMG_SIZE':224,\n",
        "    'EPOCHS':5,\n",
        "    'LEARNING_RATE':3e-4,\n",
        "    'BATCH_SIZE':32,\n",
        "    'SEED':41\n",
        "}\n",
        "\n",
        "#Fixed RandomSeed\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(CFG['SEED']) # Seed 고정\n",
        "\n",
        "#Data Pre-processing\n",
        "df = pd.read_csv('./train.csv')\n",
        "\n",
        "train_len = int(len(df) * 0.8)\n",
        "train_df = df.iloc[:train_len]\n",
        "val_df = df.iloc[train_len:]\n",
        "\n",
        "train_label_vec = train_df.iloc[:,2:].values.astype(np.float32)\n",
        "val_label_vec = val_df.iloc[:,2:].values.astype(np.float32)\n",
        "\n",
        "CFG['label_size'] = train_label_vec.shape[1]\n",
        "CustomDataset\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, img_path_list, label_list, transforms=None):\n",
        "        self.img_path_list = img_path_list\n",
        "        self.label_list = label_list\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.img_path_list[index]\n",
        "\n",
        "        image = cv2.imread(img_path)\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            image = self.transforms(image=image)['image']\n",
        "\n",
        "        if self.label_list is not None:\n",
        "            label = self.label_list[index]\n",
        "            return image, label\n",
        "        else:\n",
        "            return image\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_path_list)\n",
        "train_transform = A.Compose([\n",
        "                            A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
        "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
        "                            ToTensorV2()\n",
        "                            ])\n",
        "\n",
        "test_transform = A.Compose([\n",
        "                            A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
        "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
        "                            ToTensorV2()\n",
        "                            ])\n",
        "train_dataset = CustomDataset(train_df['path'].values, train_label_vec, train_transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
        "\n",
        "val_dataset = CustomDataset(val_df['path'].values, val_label_vec, test_transform)\n",
        "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
        "Model Define\n",
        "class BaseModel(nn.Module):\n",
        "    def __init__(self, gene_size=CFG['label_size']):\n",
        "        super(BaseModel, self).__init__()\n",
        "        self.backbone = models.resnet50(pretrained=True)\n",
        "        self.regressor = nn.Linear(1000, gene_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = self.regressor(x)\n",
        "        return x\n",
        "Train\n",
        "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
        "    model.to(device)\n",
        "    criterion = nn.MSELoss().to(device)\n",
        "\n",
        "    best_loss = 99999999\n",
        "    best_model = None\n",
        "\n",
        "    for epoch in range(1, CFG['EPOCHS']+1):\n",
        "        model.train()\n",
        "        train_loss = []\n",
        "        for imgs, labels in tqdm(iter(train_loader)):\n",
        "            imgs = imgs.float().to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(imgs)\n",
        "            loss = criterion(output, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss.append(loss.item())\n",
        "\n",
        "        _val_loss = validation(model, criterion, val_loader, device)\n",
        "        _train_loss = np.mean(train_loss)\n",
        "        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}]')\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step(_val_loss)\n",
        "\n",
        "        if best_loss > _val_loss:\n",
        "            best_loss = _val_loss\n",
        "            best_model = model\n",
        "\n",
        "    return best_mode\n",
        "def validation(model, criterion, val_loader, device):\n",
        "    model.eval()\n",
        "    val_loss = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in tqdm(iter(val_loader)):\n",
        "            imgs = imgs.float().to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            pred = model(imgs)\n",
        "\n",
        "            loss = criterion(pred, labels)\n",
        "\n",
        "            val_loss.append(loss.item())\n",
        "\n",
        "        _val_loss = np.mean(val_loss)\n",
        "\n",
        "    return _val_loss\n",
        "Run!!\n",
        "model = BaseModel()\n",
        "model.eval()\n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
        "\n",
        "infer_model = train(model, optimizer, train_loader, val_loader, scheduler, device)\n",
        "Inference\n",
        "\n",
        "test = pd.read_csv('./test.csv')\n",
        "\n",
        "test_dataset = CustomDataset(test['path'].values, None, test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
        "\n",
        "def inference(model, test_loader, device):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for imgs in tqdm(test_loader):\n",
        "            imgs = imgs.to(device).float()\n",
        "            pred = model(imgs)\n",
        "\n",
        "            preds.append(pred.detach().cpu())\n",
        "\n",
        "    preds = torch.cat(preds).numpy()\n",
        "\n",
        "    return preds\n",
        "\n",
        "preds = inference(infer_model, test_loader, device)\n",
        "Submission\n",
        "submit = pd.read_csv('./sample_submission.csv')\n",
        "submit.iloc[:, 1:] = np.array(preds).astype(np.float32)\n",
        "submit.to_csv('./baseline_submit.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swwZTABOW4n7"
      },
      "outputs": [],
      "source": [
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eINa7DFkW4qa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOpIYE2aW4rG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9g9f99kYW4si"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nd_5I_MNW4ur"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhGtMpSlW4wz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MurZeNmW4z0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uTqijqzW412"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p11mQFmjW433"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kk3YcrO_W45-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPWuVYNUW48H"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzsLegAmW5AQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSxvH8MBW5Cn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vj7gWIyaW5FE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GF_Dtb78W5G_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}